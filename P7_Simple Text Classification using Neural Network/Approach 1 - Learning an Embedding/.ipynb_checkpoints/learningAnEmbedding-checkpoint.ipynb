{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning An Embedding\n",
    "\n",
    "In this section, we will look at how we can learn a word embedding while fitting a neural network on a text classification problem.\n",
    "\n",
    "We will define a small problem where we have 10 text documents, each with a comment about a piece of work a student submitted. Each text document is classified as positive “1” or negative “0”. This is a simple sentiment analysis problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47, 10], [11, 47], [6, 45], [8, 47], [6], [15], [4, 45], [39, 11], [4, 47], [43, 42, 10, 41]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pad Sequences \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0 47 10]\n",
      " [ 0  0 11 47]\n",
      " [ 0  0  6 45]\n",
      " [ 0  0  8 47]\n",
      " [ 0  0  0  6]\n",
      " [ 0  0  0 15]\n",
      " [ 0  0  4 45]\n",
      " [ 0  0 39 11]\n",
      " [ 0  0  4 47]\n",
      " [43 42 10 41]]\n"
     ]
    }
   ],
   "source": [
    "### Find Max no of words in Whole lists of sentence \n",
    "# sent_length=8\n",
    "sent_length = max([len(sen.split(' ')) for sen in docs ])\n",
    "embedded_docs=pad_sequences(encoded_docs,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer along with Output and No Dense Layer included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lucky_Rathod\\Anaconda3\\envs\\kn_course\\lib\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Lucky_Rathod\\Anaconda3\\envs\\kn_course\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 4, 8)              400       \n",
      "=================================================================\n",
      "Total params: 400\n",
      "Trainable params: 400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Feature Representation ---- 10 Features (Vector Length)\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=sent_length))\n",
    "model.compile('adam','mse')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [-0.01808726, -0.03990116,  0.03457019, -0.0126509 ,\n",
       "          0.04557369, -0.03543545, -0.00449588,  0.04883726],\n",
       "        [-0.03252991,  0.0085272 , -0.04137795, -0.01106777,\n",
       "         -0.00585307, -0.00744376, -0.00409549, -0.02560116]],\n",
       "\n",
       "       [[ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [-0.02627642,  0.02711337, -0.02349795,  0.03750106,\n",
       "          0.04942321,  0.04389988, -0.02694153, -0.03764254],\n",
       "        [-0.01808726, -0.03990116,  0.03457019, -0.0126509 ,\n",
       "          0.04557369, -0.03543545, -0.00449588,  0.04883726]],\n",
       "\n",
       "       [[ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [-0.03164494,  0.01414958, -0.04517304, -0.0313602 ,\n",
       "         -0.02469335,  0.03314075,  0.04931677,  0.03198128],\n",
       "        [-0.01925802,  0.02505639,  0.03008204, -0.01551117,\n",
       "         -0.04835508, -0.01604   ,  0.00639134,  0.00621822]],\n",
       "\n",
       "       [[ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [ 0.03613058, -0.02672886, -0.02732114, -0.02170192,\n",
       "          0.02121514,  0.03702351, -0.04902461, -0.02809658],\n",
       "        [-0.01808726, -0.03990116,  0.03457019, -0.0126509 ,\n",
       "          0.04557369, -0.03543545, -0.00449588,  0.04883726]],\n",
       "\n",
       "       [[ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [-0.03164494,  0.01414958, -0.04517304, -0.0313602 ,\n",
       "         -0.02469335,  0.03314075,  0.04931677,  0.03198128]],\n",
       "\n",
       "       [[ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [ 0.04062695,  0.01128428,  0.02888819, -0.04443903,\n",
       "         -0.03896649, -0.03216426,  0.03043992,  0.02877078]],\n",
       "\n",
       "       [[ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [ 0.01966765, -0.0152394 ,  0.03837938,  0.04360751,\n",
       "         -0.01361995,  0.03185226, -0.0006606 ,  0.00938418],\n",
       "        [-0.01925802,  0.02505639,  0.03008204, -0.01551117,\n",
       "         -0.04835508, -0.01604   ,  0.00639134,  0.00621822]],\n",
       "\n",
       "       [[ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [-0.01301417,  0.03567186,  0.02770985,  0.03523043,\n",
       "         -0.02314265,  0.04557598,  0.00991052, -0.02308846],\n",
       "        [-0.02627642,  0.02711337, -0.02349795,  0.03750106,\n",
       "          0.04942321,  0.04389988, -0.02694153, -0.03764254]],\n",
       "\n",
       "       [[ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [ 0.03621672,  0.01339883,  0.04481817, -0.01903031,\n",
       "         -0.00732581,  0.02661328, -0.02585479,  0.02550535],\n",
       "        [ 0.01966765, -0.0152394 ,  0.03837938,  0.04360751,\n",
       "         -0.01361995,  0.03185226, -0.0006606 ,  0.00938418],\n",
       "        [-0.01808726, -0.03990116,  0.03457019, -0.0126509 ,\n",
       "          0.04557369, -0.03543545, -0.00449588,  0.04883726]],\n",
       "\n",
       "       [[ 0.04352852, -0.04865546,  0.03932909,  0.04019259,\n",
       "         -0.00509777, -0.01497339,  0.00193294, -0.02887397],\n",
       "        [ 0.01128175,  0.03908714, -0.0017774 ,  0.00612868,\n",
       "          0.03850609,  0.04932879, -0.02923722, -0.02843275],\n",
       "        [-0.03252991,  0.0085272 , -0.04137795, -0.01106777,\n",
       "         -0.00585307, -0.00744376, -0.00409549, -0.02560116],\n",
       "        [ 0.03745066,  0.02531807, -0.03011115,  0.0265233 ,\n",
       "         -0.04964393, -0.00187855, -0.04247902, -0.04119054]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03621672  0.01339883  0.04481817 -0.01903031 -0.00732581  0.02661328\n",
      "  -0.02585479  0.02550535]\n",
      " [ 0.03621672  0.01339883  0.04481817 -0.01903031 -0.00732581  0.02661328\n",
      "  -0.02585479  0.02550535]\n",
      " [-0.01808726 -0.03990116  0.03457019 -0.0126509   0.04557369 -0.03543545\n",
      "  -0.00449588  0.04883726]\n",
      " [-0.03252991  0.0085272  -0.04137795 -0.01106777 -0.00585307 -0.00744376\n",
      "  -0.00409549 -0.02560116]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(embedded_docs)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Layer with Dense Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lucky_Rathod\\Anaconda3\\envs\\kn_course\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=sent_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.999998\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(embedded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(embedded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
