{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding - Practical Implementation using Keras\n",
    "\n",
    "https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "\n",
    "See Word Embedding Intuition part to Understand How Word Embedding works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\n",
    "### sentences\n",
    "sent=[  'the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "    'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good',]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vocabulary size\n",
    "voc_size=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras offers an Embedding layer that can be used for neural networks on text data.\n",
    "\n",
    "It requires that the input data be integer encoded, so that each word is represented by a unique integer. This data preparation step can be performed using the Tokenizer API or One Hot Representation which is provided with Keras\n",
    "\n",
    "#### One Hot Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8143, 9713, 9755, 9432], [8143, 9713, 9755, 244], [8143, 2678, 9755, 7746], [3660, 246, 6445, 8285, 4368], [3660, 246, 6445, 8285, 8173], [1470, 8143, 737, 9755, 5438], [3546, 8271, 8839, 8285]]\n"
     ]
    }
   ],
   "source": [
    "### Each word will be provided with index from Dictionary\n",
    "onehot_repr=[one_hot(words,voc_size)for words in sent] \n",
    "print(onehot_repr)\n",
    "\n",
    "# the - 8143 , glass - 9713 , of - 9755 , milk - 9432"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pad Sequences\n",
    "\n",
    "Before passing One Hot representation to Embedding Layer , we have to see the length and width of mtrix should be same.\n",
    "Some sentences are small, Some are big . We need to pad 0 . If sentence is small in order to match the length of big Sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(sen.split(' ')) for sen in sent ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 8143 9713 9755 9432]\n",
      " [   0 8143 9713 9755  244]\n",
      " [   0 8143 2678 9755 7746]\n",
      " [3660  246 6445 8285 4368]\n",
      " [3660  246 6445 8285 8173]\n",
      " [1470 8143  737 9755 5438]\n",
      " [   0 3546 8271 8839 8285]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "### Find Max no of words in Whole lists of sentence \n",
    "# sent_length=8\n",
    "sent_length = max([len(sen.split(' ')) for sen in sent ])\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Layer \n",
    "\n",
    "The Embedding layer is initialized with random weights and will learn an embedding for all of the words in the training dataset.\n",
    "\n",
    "It is a flexible layer that can be used in a variety of ways, such as:\n",
    "\n",
    "1. It can be used alone to learn a word embedding that can be saved and used in another model later.\n",
    "2. It can be used as part of a deep learning model where the embedding is learned along with the model itself.\n",
    "3. It can be used to load a pre-trained word embedding model, a type of transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lucky_Rathod\\Anaconda3\\envs\\kn_course\\lib\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Lucky_Rathod\\Anaconda3\\envs\\kn_course\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 5, 10)             100000    \n",
      "=================================================================\n",
      "Total params: 100,000\n",
      "Trainable params: 100,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "\n",
    "### Feature Representation ---- 10 Features (Vector Length)\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,10,input_length=sent_length))\n",
    "model.compile('adam','mse')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output of Embedding Layer -- Embedded Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.01849422  0.02723768  0.04391457  0.03099874 -0.04433843\n",
      "   -0.01770258 -0.04808167 -0.00996188  0.02483911 -0.02960135]\n",
      "  [-0.01706839  0.04825843  0.015813    0.04609114 -0.01626893\n",
      "    0.03503921 -0.00550652 -0.00065093  0.02116298  0.01123443]\n",
      "  [ 0.01693672  0.01889813  0.04780388  0.0183457  -0.03132993\n",
      "    0.01287115  0.04079077 -0.02996605  0.01374892 -0.03480309]\n",
      "  [-0.02500593 -0.01240395  0.04258927  0.02297049 -0.03576022\n",
      "    0.01126082  0.03173603 -0.01215279  0.01983956 -0.01372912]\n",
      "  [-0.03959063  0.01205043 -0.04634528  0.00621315  0.01087252\n",
      "    0.03528966  0.00103041 -0.04187227  0.01751666  0.01359773]]\n",
      "\n",
      " [[ 0.01849422  0.02723768  0.04391457  0.03099874 -0.04433843\n",
      "   -0.01770258 -0.04808167 -0.00996188  0.02483911 -0.02960135]\n",
      "  [-0.01706839  0.04825843  0.015813    0.04609114 -0.01626893\n",
      "    0.03503921 -0.00550652 -0.00065093  0.02116298  0.01123443]\n",
      "  [ 0.01693672  0.01889813  0.04780388  0.0183457  -0.03132993\n",
      "    0.01287115  0.04079077 -0.02996605  0.01374892 -0.03480309]\n",
      "  [-0.02500593 -0.01240395  0.04258927  0.02297049 -0.03576022\n",
      "    0.01126082  0.03173603 -0.01215279  0.01983956 -0.01372912]\n",
      "  [-0.04976222  0.02760169 -0.0083145  -0.0040543  -0.03312061\n",
      "    0.01598116  0.0002475  -0.02759787  0.00843903  0.047492  ]]\n",
      "\n",
      " [[ 0.01849422  0.02723768  0.04391457  0.03099874 -0.04433843\n",
      "   -0.01770258 -0.04808167 -0.00996188  0.02483911 -0.02960135]\n",
      "  [-0.01706839  0.04825843  0.015813    0.04609114 -0.01626893\n",
      "    0.03503921 -0.00550652 -0.00065093  0.02116298  0.01123443]\n",
      "  [-0.02431725  0.04320543  0.03264556  0.00383692 -0.02289718\n",
      "   -0.00339315 -0.0095915  -0.02680845  0.02861546  0.03996805]\n",
      "  [-0.02500593 -0.01240395  0.04258927  0.02297049 -0.03576022\n",
      "    0.01126082  0.03173603 -0.01215279  0.01983956 -0.01372912]\n",
      "  [-0.03909614  0.0261325  -0.03971044  0.01383013  0.04073824\n",
      "   -0.00706546 -0.00983248 -0.01954529  0.00872342 -0.00699701]]\n",
      "\n",
      " [[-0.00090994  0.04771147 -0.02383814  0.04939394 -0.00826833\n",
      "    0.00315086  0.00600313 -0.01656829  0.00790001  0.04582028]\n",
      "  [ 0.03098649  0.03321049 -0.04541254  0.02567055 -0.02904596\n",
      "    0.01142569  0.02146304  0.03181655 -0.0043723   0.03477857]\n",
      "  [ 0.04894063  0.01111972  0.0262523  -0.0069245   0.02317906\n",
      "   -0.02079629 -0.01044278  0.03349682  0.02444445  0.00578524]\n",
      "  [-0.04195017  0.00397516  0.03302398  0.00335708  0.02621331\n",
      "    0.00230079 -0.02325879 -0.04587055 -0.02163906  0.0301018 ]\n",
      "  [ 0.02866197  0.03697893  0.01464802 -0.02484336  0.01929582\n",
      "   -0.04043581  0.01433535  0.0386143  -0.01845022 -0.0158449 ]]\n",
      "\n",
      " [[-0.00090994  0.04771147 -0.02383814  0.04939394 -0.00826833\n",
      "    0.00315086  0.00600313 -0.01656829  0.00790001  0.04582028]\n",
      "  [ 0.03098649  0.03321049 -0.04541254  0.02567055 -0.02904596\n",
      "    0.01142569  0.02146304  0.03181655 -0.0043723   0.03477857]\n",
      "  [ 0.04894063  0.01111972  0.0262523  -0.0069245   0.02317906\n",
      "   -0.02079629 -0.01044278  0.03349682  0.02444445  0.00578524]\n",
      "  [-0.04195017  0.00397516  0.03302398  0.00335708  0.02621331\n",
      "    0.00230079 -0.02325879 -0.04587055 -0.02163906  0.0301018 ]\n",
      "  [ 0.03506533  0.04442464  0.03840276  0.02632112  0.02455286\n",
      "   -0.04665392  0.03447051  0.04319254  0.04877651  0.01476741]]\n",
      "\n",
      " [[-0.02505994  0.04300386 -0.00962331 -0.0085959  -0.00482788\n",
      "    0.0180541   0.0129303   0.01486578  0.03123185 -0.04692728]\n",
      "  [-0.01706839  0.04825843  0.015813    0.04609114 -0.01626893\n",
      "    0.03503921 -0.00550652 -0.00065093  0.02116298  0.01123443]\n",
      "  [ 0.03411349 -0.04038702  0.03465087  0.02363063 -0.00629228\n",
      "   -0.03764413  0.02095613  0.01164687  0.02215066 -0.01671622]\n",
      "  [-0.02500593 -0.01240395  0.04258927  0.02297049 -0.03576022\n",
      "    0.01126082  0.03173603 -0.01215279  0.01983956 -0.01372912]\n",
      "  [-0.03558094  0.01383896  0.02360687  0.00658663 -0.01009568\n",
      "    0.02713156 -0.00941185 -0.02364031 -0.04075247 -0.01868105]]\n",
      "\n",
      " [[ 0.01849422  0.02723768  0.04391457  0.03099874 -0.04433843\n",
      "   -0.01770258 -0.04808167 -0.00996188  0.02483911 -0.02960135]\n",
      "  [-0.01201272 -0.04838418 -0.02446437 -0.03419395 -0.01993256\n",
      "    0.02061905 -0.01841327 -0.02121927 -0.03269061 -0.03535297]\n",
      "  [ 0.01124074 -0.01770334  0.01397437 -0.03161057 -0.03787405\n",
      "   -0.04256922 -0.02246482 -0.04757917 -0.03869921  0.0127557 ]\n",
      "  [-0.04846655 -0.00339309 -0.013682    0.03812795  0.02134703\n",
      "    0.00155935 -0.02121247  0.03796626  0.00775995  0.01543066]\n",
      "  [-0.04195017  0.00397516  0.03302398  0.00335708  0.02621331\n",
      "    0.00230079 -0.02325879 -0.04587055 -0.02163906  0.0301018 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(embedded_docs))  # Matrix for all sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 8143, 9713, 9755, 9432])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now every word in Sentence 0 is converted into Vector of Dimension 10\n",
    "\n",
    "0 the glass of milk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01849422  0.02723768  0.04391457  0.03099874 -0.04433843 -0.01770258\n",
      "  -0.04808167 -0.00996188  0.02483911 -0.02960135]\n",
      " [-0.01706839  0.04825843  0.015813    0.04609114 -0.01626893  0.03503921\n",
      "  -0.00550652 -0.00065093  0.02116298  0.01123443]\n",
      " [ 0.01693672  0.01889813  0.04780388  0.0183457  -0.03132993  0.01287115\n",
      "   0.04079077 -0.02996605  0.01374892 -0.03480309]\n",
      " [-0.02500593 -0.01240395  0.04258927  0.02297049 -0.03576022  0.01126082\n",
      "   0.03173603 -0.01215279  0.01983956 -0.01372912]\n",
      " [-0.03959063  0.01205043 -0.04634528  0.00621315  0.01087252  0.03528966\n",
      "   0.00103041 -0.04187227  0.01751666  0.01359773]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(embedded_docs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
